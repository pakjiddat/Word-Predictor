% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-evaluator.R
\name{ModelEvaluator}
\alias{ModelEvaluator}
\title{It is used to evaluate the accuracy and performance of the model.}
\description{
It provides methods that perform extrinsic and intrinsic model
evaluation. It also provides methods for determining the memory and time
requirements for generating the model. It also provides a method for
determining how much memory is used by the final model.
}
\details{
It provides a method that performs intrinsic model evaluation based
on Perplexity. It also provides a method that performs extrinsic model
evalation based on accuracy. It provides a method for determining how much
memory and time is needed to generate a model for different input data
sizes. It provides a method for determining how much memory is needed by
the final model.
}
\section{Super class}{
\code{\link[wordpredictor:TextFileProcessor]{wordpredictor::TextFileProcessor}} -> \code{ModelEvaluator}
}
\section{Public fields}{
\if{html}{\out{<div class="r6-fields">}}
\describe{
\item{\code{tp}}{The transition probabilities data frame.}

\item{\code{wl}}{The list of unique words.}

\item{\code{dp}}{The default probability is equal to 1/(N+V), where N is the
number of words in the sentence, V is the number of words in the
vocabulary.}

\item{\code{model}}{The maximum number of ngrams supported by the model.}

\item{\code{dc_opts}}{The options for the data cleaner object.
min_words -> The minimum number of words per sentence.
line_count -> The number of lines to read and clean at a time.
sw_file -> The stop words file path.
bad_file -> The bad words file path.
to_lower -> If the words should be converted to lower case.
remove_stop -> If stop words should be removed.
remove_punct -> If punctuation symbols should be removed.
remove_non_dict -> If non dictionary words should be removed.
remove_non_alpha -> If non alphabet symbols should be removed.
remove_extra_space -> If leading, trailing and double spaces
should be removed.
remove_bad -> If bad words should be removed}

\item{\code{tg_opts}}{The options for the token generator obj.
n -> The ngram size.
save_ngrams -> If the ngram data should be saved.
min_freq -> All ngrams with frequency less than min_freq are
ignored.
line_count -> The number of lines to process at a time.
stem_words -> If words should be converted to their stem.
dir -> The dir where the output file should be saved.
format -> The format for the output. There are two options.
'plain' -> The data is stored in plain text.
'obj' -> The data is stored as a R obj.}

\item{\code{ssize}}{The sample size in Mb.}

\item{\code{ddir}}{The folder containing the data files}

\item{\code{mdir}}{The folder containing the model files}
}
\if{html}{\out{</div>}}
}
\section{Methods}{
\subsection{Public methods}{
\itemize{
\item \href{#method-new}{\code{ModelEvaluator$new()}}
\item \href{#method-performance_comparision}{\code{ModelEvaluator$performance_comparision()}}
\item \href{#method-performance_evaluation}{\code{ModelEvaluator$performance_evaluation()}}
\item \href{#method-load_config}{\code{ModelEvaluator$load_config()}}
\item \href{#method-load_model}{\code{ModelEvaluator$load_model()}}
\item \href{#method-save_config}{\code{ModelEvaluator$save_config()}}
\item \href{#method-generate_model}{\code{ModelEvaluator$generate_model()}}
\item \href{#method-intrinsic_evaluation}{\code{ModelEvaluator$intrinsic_evaluation()}}
\item \href{#method-extrinsic_evaluation}{\code{ModelEvaluator$extrinsic_evaluation()}}
\item \href{#method-predict_word}{\code{ModelEvaluator$predict_word()}}
\item \href{#method-get_word_prob}{\code{ModelEvaluator$get_word_prob()}}
\item \href{#method-calc_perplexity}{\code{ModelEvaluator$calc_perplexity()}}
\item \href{#method-generate_clean_sample}{\code{ModelEvaluator$generate_clean_sample()}}
\item \href{#method-clone}{\code{ModelEvaluator$clone()}}
}
}
\if{html}{
\out{<details ><summary>Inherited methods</summary>}
\itemize{
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="display_msg">}\href{../../wordpredictor/html/TextFileProcessor.html#method-display_msg}{\code{wordpredictor::TextFileProcessor$display_msg()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="format_size">}\href{../../wordpredictor/html/TextFileProcessor.html#method-format_size}{\code{wordpredictor::TextFileProcessor$format_size()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="post_process">}\href{../../wordpredictor/html/TextFileProcessor.html#method-post_process}{\code{wordpredictor::TextFileProcessor$post_process()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="pre_process">}\href{../../wordpredictor/html/TextFileProcessor.html#method-pre_process}{\code{wordpredictor::TextFileProcessor$pre_process()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="process">}\href{../../wordpredictor/html/TextFileProcessor.html#method-process}{\code{wordpredictor::TextFileProcessor$process()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="process_file">}\href{../../wordpredictor/html/TextFileProcessor.html#method-process_file}{\code{wordpredictor::TextFileProcessor$process_file()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="read_file">}\href{../../wordpredictor/html/TextFileProcessor.html#method-read_file}{\code{wordpredictor::TextFileProcessor$read_file()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="read_lines">}\href{../../wordpredictor/html/TextFileProcessor.html#method-read_lines}{\code{wordpredictor::TextFileProcessor$read_lines()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="read_obj">}\href{../../wordpredictor/html/TextFileProcessor.html#method-read_obj}{\code{wordpredictor::TextFileProcessor$read_obj()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="save_obj">}\href{../../wordpredictor/html/TextFileProcessor.html#method-save_obj}{\code{wordpredictor::TextFileProcessor$save_obj()}}\out{</span>}
\item \out{<span class="pkg-link" data-pkg="wordpredictor" data-topic="TextFileProcessor" data-id="write_file">}\href{../../wordpredictor/html/TextFileProcessor.html#method-write_file}{\code{wordpredictor::TextFileProcessor$write_file()}}\out{</span>}
}
\out{</details>}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-new"></a>}}
\if{latex}{\out{\hypertarget{method-new}{}}}
\subsection{Method \code{new()}}{
It initializes the current object. It is used to set the
maximum ngram number, sample size, input file name, data cleaner
options and verbose option.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$new(
  model = 4,
  ssize = 30,
  ddir = "./data",
  mdir = "./data/models",
  dc_opts = list(),
  tg_opts = list(),
  verbose = 0
)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{model}}{The maximum ngram number supported by the model.}

\item{\code{ssize}}{The sample size in Mb.}

\item{\code{ddir}}{The data directory.}

\item{\code{mdir}}{The model directory.}

\item{\code{dc_opts}}{The data cleaner options.}

\item{\code{tg_opts}}{The token generator options.}

\item{\code{verbose}}{If progress information should be displayed.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-performance_comparision"></a>}}
\if{latex}{\out{\hypertarget{method-performance_comparision}{}}}
\subsection{Method \code{performance_comparision()}}{
It compares the performance of the specified models by
plotting the performance statistics. The models are specified with
the type parameter.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$performance_comparision(type, opts)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{type}}{The models to compare. It can be:
'basic' -> One model for each ngram.
'grouped' -> One model for each group and ngram. For
e.g For data size 5 Mb, there are 3 models for the ngrams 2:4.}

\item{\code{opts}}{The options for plotting the data.
'group' -> The field to group by.
'title' -> The main plot title.
'subtitle' -> The plot sub title.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The performance stats.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-performance_evaluation"></a>}}
\if{latex}{\out{\hypertarget{method-performance_evaluation}{}}}
\subsection{Method \code{performance_evaluation()}}{
For each model it performs intrinsic and extrinsic
evaluation. It also measures the memory usage and time taken. The
performance metrics are displayed in 5 plots on one page. Performance
statistics are saved to the file pstats.RDS.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$performance_evaluation()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-load_config"></a>}}
\if{latex}{\out{\hypertarget{method-load_config}{}}}
\subsection{Method \code{load_config()}}{
It loads the given model configuration file.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$load_config(fn)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{fn}}{The config file name.}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-load_model"></a>}}
\if{latex}{\out{\hypertarget{method-load_model}{}}}
\subsection{Method \code{load_model()}}{
It loads the model located at the mdir location
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$load_model()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-save_config"></a>}}
\if{latex}{\out{\hypertarget{method-save_config}{}}}
\subsection{Method \code{save_config()}}{
It saves the model configuration to the models
subdirectory of the given directory.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$save_config()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-generate_model"></a>}}
\if{latex}{\out{\hypertarget{method-generate_model}{}}}
\subsection{Method \code{generate_model()}}{
It generates the model for the given ngram number,
data sample size, data cleaning options and input file.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$generate_model()}\if{html}{\out{</div>}}
}

}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-intrinsic_evaluation"></a>}}
\if{latex}{\out{\hypertarget{method-intrinsic_evaluation}{}}}
\subsection{Method \code{intrinsic_evaluation()}}{
Evaluates the model using intrinsic evaluation based on
Perplexity. First a validation data set containing 1000 lines is
generated. It is then cleaned. 20 random sentences are taken. For
each sentence, Perplexity of all the words is calculated.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$intrinsic_evaluation()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
The minumum, maximum and mean Perplexity score.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-extrinsic_evaluation"></a>}}
\if{latex}{\out{\hypertarget{method-extrinsic_evaluation}{}}}
\subsection{Method \code{extrinsic_evaluation()}}{
Evaluates the model using extrinsic evaluation based on
Accuracy. First a validation data set containing 1000 lines is
generated. It is then cleaned. 20 random sentences are taken. For
each sentence, the model is used to predict the next word. The
accuracy stats are returned. A prediction is considered to be correct
if one of the predicted words matched the actual word.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$extrinsic_evaluation()}\if{html}{\out{</div>}}
}

\subsection{Returns}{
The number of correct and incorrect predictions.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-predict_word"></a>}}
\if{latex}{\out{\hypertarget{method-predict_word}{}}}
\subsection{Method \code{predict_word()}}{
Predicts the new word given a list of 1, 2 or 3 previous
words. It checks the given n words in the transition probabilities
data. If there is a match, the top 3 next words with highest
probabilities are returned. If there is no match, then the last n-1
previous words are checked. This process is continued until the last
word is checked. If there is no match, then empty result is returned.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$predict_word(words, count = 3, dc = NULL)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{words}}{A character vector of previous words or a single vector
containing the previous word text.}

\item{\code{count}}{The number of results to return.}

\item{\code{dc}}{A DataCleaner object. If it is given, then the given words
are cleaned. If the stem_words option was set in the TokenGenerator
object configuration for the current model, then the words are
converted to their stems.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The top 3 predicted words along with their probabilities.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-get_word_prob"></a>}}
\if{latex}{\out{\hypertarget{method-get_word_prob}{}}}
\subsection{Method \code{get_word_prob()}}{
Calculates the probability of the given word given the
previous model-1 words, where model is the maximum ngram number. It
looks up the probability of a word given n previous words. The
previous n words are converted to numeric hash using digest2int
function. The hash is looked up in a data frame of transition
probabilities. The word is converted to a number by checking its
position in a list of unique words. If the hash and the word position
were found, then the probability of the previous word and hash is
returned. If it was not found, then the hash of the n-1 previous
words is taken and the processed is repeated. If the data was not
found in the data frame, then the word probability is returned. This
is known as backoff. If the word probability could not be found then
the default probability is returned. The default probability is
calculated as 1/(N+V), Where N = number of words in corpus and V is
the number of dictionary words.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$get_word_prob(word, pw)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{word}}{The word whoose probability is to be calculated.}

\item{\code{pw}}{The previous words.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The probability of the word given the previous words.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-calc_perplexity"></a>}}
\if{latex}{\out{\hypertarget{method-calc_perplexity}{}}}
\subsection{Method \code{calc_perplexity()}}{
The Perplexity for the given sentence is calculated. For
each word, the probability of the word given the previous words is
calculated. The probabilities are multiplied and then inverted. The
nth root of the result is the perplexity, where n is the number of
words in the sentence. If the stem_words tokenization option was
specified, then the previous words are converted to their stem.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$calc_perplexity(words)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{words}}{The list of words.}
}
\if{html}{\out{</div>}}
}
\subsection{Returns}{
The perplexity of the given list of words.
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-generate_clean_sample"></a>}}
\if{latex}{\out{\hypertarget{method-generate_clean_sample}{}}}
\subsection{Method \code{generate_clean_sample()}}{
Generates a sample file of given size from the main
train.txt file file name. The file is cleaned and saved.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$generate_clean_sample(ss, ic, t)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{ss}}{The number of lines or proportion of lines to sample.}

\item{\code{ic}}{If the sample file should be cleaned.}

\item{\code{t}}{The type of sample. It can be:
'tr' -> training
'te' -> testing
'va' -> validation}
}
\if{html}{\out{</div>}}
}
}
\if{html}{\out{<hr>}}
\if{html}{\out{<a id="method-clone"></a>}}
\if{latex}{\out{\hypertarget{method-clone}{}}}
\subsection{Method \code{clone()}}{
The objects of this class are cloneable with this method.
\subsection{Usage}{
\if{html}{\out{<div class="r">}}\preformatted{ModelEvaluator$clone(deep = FALSE)}\if{html}{\out{</div>}}
}

\subsection{Arguments}{
\if{html}{\out{<div class="arguments">}}
\describe{
\item{\code{deep}}{Whether to make a deep clone.}
}
\if{html}{\out{</div>}}
}
}
}
