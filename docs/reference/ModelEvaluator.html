<!-- Generated by pkgdown: do not edit by hand -->
<!DOCTYPE html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<title>It performs extrinsic and intrinsic evaluation of a n-gram model — ModelEvaluator • Word Predictor</title>


<!-- jquery -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.4.1/jquery.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>
<!-- Bootstrap -->

<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/css/bootstrap.min.css" integrity="sha256-bZLfwXAP04zRMK2BjiO8iu9pf4FbLqX6zitd+tIvLhE=" crossorigin="anonymous" />

<script src="https://cdnjs.cloudflare.com/ajax/libs/twitter-bootstrap/3.4.1/js/bootstrap.min.js" integrity="sha256-nuL8/2cJ5NDSSwnKD8VqreErSWHtnEP9E7AySL+1ev4=" crossorigin="anonymous"></script>

<!-- bootstrap-toc -->
<link rel="stylesheet" href="../bootstrap-toc.css">
<script src="../bootstrap-toc.js"></script>

<!-- Font Awesome icons -->
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous" />

<!-- clipboard.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script>

<!-- headroom.js -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script>

<!-- pkgdown -->
<link href="../pkgdown.css" rel="stylesheet">
<script src="../pkgdown.js"></script>




<meta property="og:title" content="It performs extrinsic and intrinsic evaluation of a n-gram model — ModelEvaluator" />
<meta property="og:description" content="It provides methods for performing extrinsic and intrinsic
evaluation. Intrinsic evaluation is based on calculation of Perplexity.
Extrinsic evaluation involves determining the percentage of correct next word
predictions." />




<!-- mathjax -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script>

<!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->



  </head>

  <body data-spy="scroll" data-target="#toc">
    <div class="container template-reference-topic">
      <header>
      <div class="navbar navbar-default navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar" aria-expanded="false">
        <span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <span class="navbar-brand">
        <a class="navbar-link" href="../index.html">Word Predictor</a>
        <span class="version label label-default" data-toggle="tooltip" data-placement="bottom" title="Released version">1.0.0</span>
      </span>
    </div>

    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="../index.html">
    <span class="fas fa fas fa-home fa-lg"></span>
     
  </a>
</li>
<li>
  <a href="../reference/index.html">Reference</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Articles
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="../articles/features.html">features</a>
    </li>
    <li>
      <a href="../articles/overview.html">overview</a>
    </li>
  </ul>
</li>
<li>
  <a href="../news/index.html">Changelog</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        <li>
  <a href="https://github.com/pakjiddat/word-predictor/">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
      
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

      

      </header>

<div class="row">
  <div class="col-md-9 contents">
    <div class="page-header">
    <h1>It performs extrinsic and intrinsic evaluation of a n-gram model</h1>
    <small class="dont-index">Source: <a href='https://github.com/pakjiddat/word-predictor/blob/master/R/model-evaluator.R'><code>R/model-evaluator.R</code></a></small>
    <div class="hidden name"><code>ModelEvaluator.Rd</code></div>
    </div>

    <div class="ref-description">
    <p>It provides methods for performing extrinsic and intrinsic
evaluation. Intrinsic evaluation is based on calculation of Perplexity.
Extrinsic evaluation involves determining the percentage of correct next word
predictions.</p>
    </div>



    <h2 class="hasAnchor" id="details"><a class="anchor" href="#details"></a>Details</h2>

    <p>Before performing the intrinsic and extrinsic model evaluation, a
validation file must be first generated. This can be done using the Generator
class. Each line in the validation file is evaluated. For intrinsic
evaluation Perplexity for the line is calculated. An overall summary of the
Perplexity calculations is returned. It includes the min, max and mean
Perplexity. For extrinsic evaluation, next word prediction is performed on
each line. If the actual next word is one of the three predicted next words,
then the prediction is considered to be accurate. The extrinsic evaluation
returns the percentage of correct and incorrect predictions.</p>
    <h2 class="hasAnchor" id="super-class"><a class="anchor" href="#super-class"></a>Super class</h2>

    <p><code><a href='TextFileProcessor.html'>wordpredictor::TextFileProcessor</a></code> -&gt; <code>ModelEvaluator</code></p>
    <h2 class="hasAnchor" id="methods"><a class="anchor" href="#methods"></a>Methods</h2>

    
<h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Public methods</h3>

<ul>
<li><p><a href='#method-new'><code>ModelEvaluator$new()</code></a></p></li>
<li><p><a href='#method-compare_performance'><code>ModelEvaluator$compare_performance()</code></a></p></li>
<li><p><a href='#method-plot_stats'><code>ModelEvaluator$plot_stats()</code></a></p></li>
<li><p><a href='#method-evaluate_performance'><code>ModelEvaluator$evaluate_performance()</code></a></p></li>
<li><p><a href='#method-intrinsic_evaluation'><code>ModelEvaluator$intrinsic_evaluation()</code></a></p></li>
<li><p><a href='#method-extrinsic_evaluation'><code>ModelEvaluator$extrinsic_evaluation()</code></a></p></li>
<li><p><a href='#method-clone'><code>ModelEvaluator$clone()</code></a></p></li>
</ul>
<p><details open ><summary>Inherited methods</summary>
<ul>
</ul>
</details>

<hr>
<a id="method-new"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>new()</code></h3>
<p>It initializes the current object. It is used to set the
model file name and verbose options.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>new</span><span class='op'>(</span>mf <span class='op'>=</span> <span class='cn'>NULL</span>, ve <span class='op'>=</span> <span class='fl'>0</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>mf</code></dt><dd><p>The model file name.</p></dd>

<dt><code>ve</code></dt><dd><p>If progress information should be displayed.</p></dd>

</dl><p></div></p>
<p><hr>
<a id="method-compare_performance"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>compare_performance()</code></h3>
<p>It compares the performance of the models in the given
folder. The performance of the model is compared for the 4 metric
which are time taken, memory used, Perplexity and accuracy. The
performance comparision is displayed on plots. 4 plots are displayed.
One for each performance metric. A fifth plot shows the variation of
Perplexity with accuracy. All 5 plots are plotted on one page.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>compare_performance</span><span class='op'>(</span><span class='va'>opts</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>opts</code></dt><dd><p>The options for comparing model performance.
<ul>
<li><p><strong>save_to</strong>. The graphics device to save the plot to.
NULL implies plot is printed.</p></li>
<li><p><strong>dir</strong>. The directory where the plot and stats will be saved.</p></li>
<li><p><strong>mdir</strong>. The directory containing the model files.</p></li>
</ul></p></dd>

</dl><p></div></p>
<p><hr>
<a id="method-plot_stats"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>plot_stats()</code></h3>
<p>It plots the given stats on 5 plots. The plots are
displayed on a single page. The 4 performance metrics which are time
taken, memory, Perplexity and accuracy are plotted against the model
name. Another plot compares Perplexity with accuracy for each model.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>plot_stats</span><span class='op'>(</span><span class='va'>data</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>data</code></dt><dd><p>The data to plot</p></dd>

</dl><p></div></p>
<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Returns</h4>
<p>The ggplot object is returned.</p>
<p><hr>
<a id="method-evaluate_performance"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>evaluate_performance()</code></h3>
<p>It performs intrinsic and extrinsic evaluation for the
given model. It also measures the memory usage and time taken. The
performance metrics are displayed in 5 plots on one page. Performance
statistics are saved to the model object.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>evaluate_performance</span><span class='op'>(</span><span class='va'>lc</span>, <span class='va'>fn</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>lc</code></dt><dd><p>The number of lines of text in the validation file to be
used for the evaluation.</p></dd>

<dt><code>fn</code></dt><dd><p>The name of the validation file. If it does not exist, then
the default file validation-clean.txt is checked in the models
folder</p></dd>

</dl><p></div></p>
<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Returns</h4>
<p>The performance stats are returned.</p>
<p><hr>
<a id="method-intrinsic_evaluation"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>intrinsic_evaluation()</code></h3>
<p>Evaluates the model using intrinsic evaluation based on
Perplexity. The given number of sentences are taken from the
validation file. For each sentence, the Perplexity is calculated.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>intrinsic_evaluation</span><span class='op'>(</span><span class='va'>lc</span>, <span class='va'>fn</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>lc</code></dt><dd><p>The number of lines of text in the validation file to be
used for the evaluation.</p></dd>

<dt><code>fn</code></dt><dd><p>The name of the validation file. If it does not exist, then
the default file validation-clean.txt is checked in the models
folder</p></dd>

</dl><p></div></p>
<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Returns</h4>
<p>The min, max and mean Perplexity score.</p>
<p><hr>
<a id="method-extrinsic_evaluation"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>extrinsic_evaluation()</code></h3>
<p>Evaluates the model using extrinsic evaluation based on
Accuracy. The given number of sentences are taken from the validation
file. For each sentence, the model is used to predict the next word.
The accuracy stats are returned. A prediction is considered to be
correct if one of the predicted words matches the actual word.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>extrinsic_evaluation</span><span class='op'>(</span><span class='va'>lc</span>, <span class='va'>fn</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>lc</code></dt><dd><p>The number of lines of text in the validation file to be
used for the evaluation.</p></dd>

<dt><code>fn</code></dt><dd><p>The name of the validation file.</p></dd>

</dl><p></div></p>
<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Returns</h4>
<p>The number of correct and incorrect predictions.</p>
<p><hr>
<a id="method-clone"></a></p><h3 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Method <code>clone()</code></h3>
<p>The objects of this class are cloneable with this method.</p><h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Usage</h4>
<p><div class="r"></p><pre><span class='va'>ModelEvaluator</span><span class='op'>$</span><span class='fu'>clone</span><span class='op'>(</span>deep <span class='op'>=</span> <span class='cn'>FALSE</span><span class='op'>)</span></pre><p></div></p>

<h4 class='hasAnchor' id='arguments'><a class='anchor' href='#arguments'></a>Arguments</h4>
<p><div class="arguments"></p><dl>
<dt><code>deep</code></dt><dd><p>Whether to make a deep clone.</p></dd>

</dl><p></div></p>



  </div>
  <div class="col-md-3 hidden-xs hidden-sm" id="pkgdown-sidebar">
    <nav id="toc" data-toggle="toc" class="sticky-top">
      <h2 data-toc-skip>Contents</h2>
    </nav>
  </div>
</div>


      <footer>
      <div class="copyright">
  <p>Developed by Nadir Latif.</p>
</div>

<div class="pkgdown">
  <p>Site built with <a href="https://pkgdown.r-lib.org/">pkgdown</a> 1.6.1.</p>
</div>

      </footer>
   </div>

  


  </body>
</html>


