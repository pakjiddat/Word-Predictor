[{"path":"https://pakjiddat.github.io/word-predictor/LICENSE.html","id":null,"dir":"","previous_headings":"","what":"MIT License","title":"MIT License","text":"Copyright (c) 2021 Nadir Latif Permission hereby granted, free charge, person obtaining copy software associated documentation files (“Software”), deal Software without restriction, including without limitation rights use, copy, modify, merge, publish, distribute, sublicense, /sell copies Software, permit persons Software furnished , subject following conditions: copyright notice permission notice shall included copies substantial portions Software. SOFTWARE PROVIDED “”, WITHOUT WARRANTY KIND, EXPRESS IMPLIED, INCLUDING LIMITED WARRANTIES MERCHANTABILITY, FITNESS PARTICULAR PURPOSE NONINFRINGEMENT. EVENT SHALL AUTHORS COPYRIGHT HOLDERS LIABLE CLAIM, DAMAGES LIABILITY, WHETHER ACTION CONTRACT, TORT OTHERWISE, ARISING , CONNECTION SOFTWARE USE DEALINGS SOFTWARE.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Features","text":"document describes features provided wordpredictor package. first describes generate n-gram models. Next describes evaluate performance n-gram models. Finally describes make word predictions using n-gram model.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"model-generation","dir":"Articles","previous_headings":"","what":"Model Generation","title":"Features","text":"wordpredictor package provides several classes can used generate n-gram models. classes may used generate n-gram models step step. alternative use ModelGenerator class combines steps provides single method generating n-gram models. following steps involved generating n-gram models:","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"data-exploration","dir":"Articles","previous_headings":"Model Generation","what":"Data Exploration","title":"Features","text":"first step generating n-gram model data exploration. involves determining type textual content various text related statistics. type text may news content, blog posts, Twitter feeds, product reviews, customer chat history etc. Example text related statistics line count, word count, average line length input file size. also important determine unwanted words symbols data vulgar words, punctuation symbols, non-alphabetical symbols etc. wordpredictor package provides DataAnalyzer class can used find statistics input data. following example shows get statistics text files within folder: word count text file can fetched using command: cat file-name | wc -w. command work Unix based systems.","code":"# The required files rf <- c(   \"test.txt\",   \"validate.txt\",   \"validate-clean.txt\",   \"test-clean.txt\" ) # The test environment is setup ed <- setup_env(rf, ve)  # The DataAnalyzer object is created da <- DataAnalyzer$new(ve = ve) # Information on all text files in the ed folder is returned fi <- da$get_file_info(ed) # The file information is printed print(fi) #> $file_stats #>                                   fn total_lc max_ll min_ll mean_ll   size #> 1     /tmp/RtmpoZ8ia5/test-clean.txt       73     50     25      39 2.8 Kb #> 2           /tmp/RtmpoZ8ia5/test.txt       73     51     28      41   3 Kb #> 3 /tmp/RtmpoZ8ia5/validate-clean.txt       75     48     10      37 2.8 Kb #> 4       /tmp/RtmpoZ8ia5/validate.txt       73     50     31      40 2.9 Kb #>  #> $overall_stats #>   total_lc max_ll min_ll mean_ll total_s #> 1      294     51     31      41 11.5 Kb  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"data-sampling","dir":"Articles","previous_headings":"Model Generation","what":"Data Sampling","title":"Features","text":"next step generate training, testing validation samples input text file. many input text files, can combined single file using command: cat file-1 file-2 file3 > output-file. contents combined text file may need randomized. wordpredictor package provides DataSampler class can used generate random sample containing given number lines. following example shows generate random sample size 10 Mb input text file: Usually need train data set generating n-gram model. test data set testing model validation data set evaluating performance model. following example shows generate train, test validation files. train file contains first 80% lines, test set contains next 10% lines. remaining lines validation set. data validation file must different data train file. Otherwise can result -fitting model. model -fitted, model evaluation results exaggerated, overly optimistic unreliable. care taken ensure data validation train files different. example, dir parameter directory containing input.txt file generated test, validation train data files.","code":"# The required files rf <- c(\"input.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The sample size as a proportion of the input.txt file ssize <- 0.1 # The data file path dfp <- paste0(ed, \"/input.txt\")  # The object size is formatted obj_size <- file.size(dfp)/10^6 # The proportion of data to sample prop <- (ssize/obj_size) # An object of class DataSampler is created ds <- DataSampler$new(dir = ed, ve = ve) # The sample file is generated. # The randomized sample is saved to the file train.txt in the ed folder ds$generate_sample(     fn =  \"input.txt\",     ss = prop,     ic = F,     ir = T,     ofn = \"train.txt\",     is = T )  # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"input.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # An object of class DataSampler is created ds <- DataSampler$new(dir = ed, ve = ve) # The train, test and validation files are generated ds$generate_data(     fn =  \"input.txt\",     percs = list(         \"train\" = 0.8,         \"test\" = 0.1,         \"validate\" = 0.1     ) )  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"data-cleaning","dir":"Articles","previous_headings":"Model Generation","what":"Data Cleaning","title":"Features","text":"next step remove unwanted symbols words input text file. reduces memory requirement n-gram model makes efficient. Example unwanted words vulgar words, words part vocabulary, punctuation, numbers, non-printable characters extra spaces. wordpredictor package provides DataCleaner class can used remove unwanted words symbols text files. following example shows clean given text file: clean_file method reads certain number lines time, cleans lines text saves output text file. can used cleaning large text files.","code":"# The required files rf <- c(\"input.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The data file path fn <- paste0(ed, \"/input.txt\") # The clean file path cfn <- paste0(ed, \"/input-clean.txt\") # The data cleaning options dc_opts = list(     \"min_words\" = 2,     \"to_lower\" = T,     \"remove_stop\" = F,     \"remove_punct\" = T,     \"remove_non_dict\" = T,     \"remove_non_alpha\" = T,     \"remove_extra_space\" = T,     \"remove_bad\" = F,     \"output_file\" = cfn ) # The data cleaner object is created dc <- DataCleaner$new(fn, dc_opts, ve = ve) # The sample file is cleaned and saved as input-clean.txt in the ed dir dc$clean_file()  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"tokenization","dir":"Articles","previous_headings":"Model Generation","what":"Tokenization","title":"Features","text":"next step generate n-gram tokens cleaned text file. TokenGenerator class allows generating n-gram tokens given size given input text file. following example shows generate n-grams tokens size 1,2,3 4: code generates files n1.RDS, n2.RDS, n3.RDS n4.RDS data directory. files contains n-gram tokens along frequencies. N-grams larger size provide context. Usually n-grams size 4 generated. Two important customization options supported TokenGenerator class min_freq stem_words. min_freq sets minimum frequency n-gram tokens. n-gram tokens frequency less min_freq excluded. stem_words option used transform n-gram prefix components stems. next word transformed. n-gram token frequencies may analyzed using DataAnalyzer class. following example displays top occurring 2-gram tokens:  following example shows distribution word frequencies:  following example returns top 10 2-gram tokens start and_:","code":"# The required files rf <- c(\"test-clean.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The test file path fn <- paste0(ed, \"/test-clean.txt\") # The n-grams are generated for (n in 1:4) {   # The ngram number is set   tg_opts = list(\"n\" = n, \"save_ngrams\" = T, dir = ed)   # The TokenGenerator object is created   tg <- TokenGenerator$new(fn, tg_opts, ve = ve)   # The ngram tokens are generated   tg$generate_tokens() }  # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"n2.RDS\") # The test environment is setup ed <- setup_env(rf, ve)  # The ngram file name fn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(fn, ve = ve) # The top features plot is checked df <- da$plot_n_gram_stats(opts = list(     \"type\" = \"top_features\",     \"n\" = 10,     \"save_to\" = \"png\",     \"dir\" = \"./reference/figures\" ))  # The output file path fn <- paste0(\"./reference/figures/top_features.png\") knitr::include_graphics(fn) # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"n2.RDS\") # The test environment is setup ed <- setup_env(rf, ve)  # The ngram file name fn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(fn, ve = ve) # The top features plot is checked df <- da$plot_n_gram_stats(opts = list(     \"type\" = \"coverage\",     \"n\" = 10,     \"save_to\" = \"png\",     \"dir\" = \"./reference/figures\" ))  # The output file path fn <- paste0(\"./reference/figures/coverage.png\") knitr::include_graphics(fn) # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"n2.RDS\") # The test environment is setup ed <- setup_env(rf, ve)  # The ngram file name fn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(ve = ve) # Bi-grams starting with \"and_\" are returned df <- da$get_ngrams(fn = fn, c = 10, pre = \"^and_*\") # The data frame is sorted by frequency df <- df[order(df$freq, decreasing = T),] # The first 10 rows of the data frame are printed knitr::kable(df[1:10,], col.names = c(\"Prefix\", \"Frequency\")) # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"transition-probabilities","dir":"Articles","previous_headings":"Model Generation","what":"Transition Probabilities","title":"Features","text":"next step generating n-gram model generate transition probabilities (tp) n-gram files. TPGenerator class used generate tps. n-gram token file corresponding tp file generated. tp files combined single file containing tp data n-grams size 1, 2, 3, 4 etc. following example shows generate combined tps n-grams size 1, 2, 3 4: code produces file model-4.RDS.","code":"# The required files rf <- c(\"n1.RDS\", \"n2.RDS\", \"n3.RDS\", \"n4.RDS\") # The test environment is setup ed <- setup_env(rf, ve) # The TPGenerator object is created tp <- TPGenerator$new(opts = list(n = 4, dir = ed), ve = ve) # The combined transition probabilities are generated tp$generate_tp()  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"the-model-file","dir":"Articles","previous_headings":"Model Generation","what":"The model file","title":"Features","text":"final step generate n-gram model file files generated previous steps. Model class contains method load_model, reads combined tps files files used model. instance Model class represents n-gram model.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"generating-the-model-in-one-step","dir":"Articles","previous_headings":"Model Generation","what":"Generating the model in one step","title":"Features","text":"previous steps may combined single step. ModelGenerator class allows generating final n-gram model using single method call. following example generates n-gram model using default data cleaning tokenization options:","code":"# The required files rf <- c(\"input.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The following code generates n-gram model using default options for data # cleaning and tokenization. See the following section on how to customize these # options. Note that input.txt is the name of the input data file. It should be # present in the data directory. dir is the directory containing the input and output files. It is set to the path of the environment directory, ed.  # ModelGenerator class object is created mg <- ModelGenerator$new(     name = \"def-model\",     desc = \"N-gram model generating using default options\",     fn = \"def-model.RDS\",     df = \"input.txt\",     n = 4,     ssize = 0.1,     dir = ed,     dc_opts = list(),     tg_opts = list(),     ve = ve )  # Generates n-gram model. The output is the file def-model.RDS mg$generate_model()  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"evaluating-the-model-performance","dir":"Articles","previous_headings":"","what":"Evaluating the model performance","title":"Features","text":"wordpredictor package provides ModelEvaluator class evaluating performance generated n-gram model. Intrinsic Extrinsic evaluation supported. Also performance several n-gram models may compared. following example performs Intrinsic evaluation. measures Perplexity score sentence validation.txt file, generated data sampling step. returns minimum, mean maximum Perplexity score line. following example performs Extrinsic evaluation. measures accuracy score sentence validation.txt file. sentence model used predict last word sentence given previous words. last word correctly predicted, prediction considered accurate.","code":"# The required files rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The path to the cleaned validation file vfn <- paste0(ed, \"/validate-clean.txt\") # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed on first 20 lines stats <- me$intrinsic_evaluation(lc = 20, fn = vfn)  # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The path to the cleaned validation file vfn <- paste0(ed, \"/validate-clean.txt\") # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed on first 100 lines stats <- me$extrinsic_evaluation(lc = 100, fn = vfn)  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/features.html","id":"making-word-predictions","dir":"Articles","previous_headings":"","what":"Making word predictions","title":"Features","text":"n-gram model generated previous step can used predict next word given set words. following example shows predict next word. returns 3 possible next words along probabilities.","code":"# The required files rf <- c(\"def-model.RDS\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # An object of class ModelPredictor is created. The mf parameter is the name of # the model file that was generated in the previous example. mp <- ModelPredictor$new(mf = mfn, ve = ve) # Given the words: \"how are\", the next word is predicted. The top 3 most likely # next words are returned along with their respective probabilities. res <- mp$predict_word(words = \"how are\", 3)  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"introduction","dir":"Articles","previous_headings":"","what":"Introduction","title":"Overview","text":"document describes theory behind n-gram models generated wordpredictor package. also provides code examples describe use package. goal wordpredictor package provide flexible easy use framework generating n-gram models word prediction. package allows generating n-gram models. also allows exploring n-gram frequencies using plots. Additionally provides methods measuring n-gram model performance using Perplexity accuracy. n-gram model may customized using several options n-gram size, data cleaning options options converting text tokens.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"how-the-model-works","dir":"Articles","previous_headings":"","what":"How the model works","title":"Overview","text":"n-gram model generated wordpredictor package uses Markov model approximating language model. means probability word depends probability n-1 previous words. Maximum Likelihood Estimation (MLE) used calculate probability word. probability word calculated regarding word last component n-gram. total number occurrences n-gram divided total number occurrences (n-1)-gram. gives probability word. n-gram model generated steps. first step, input data cleaned. Unwanted symbols words removed input data. next step, cleaned data file read. N-grams extracted file, starting 1-grams configured n-gram size. 1-gram, 2-gram, 3-gram etc tokens saved separate files along frequency. 3-gram file contains extracted 3-grams respective frequencies. next step generate transition probability tables n-gram file. 1-gram file transition probability table simply list unique words along word frequencies. n-gram files, transition probability table data frame 3 columns. hash n-gram prefixes, next word id next word probability. n-gram prefix set n-1 components last component. n-1 components combined using “_” converted numeric hash value using digest2Int method digest package. next word id numeric index next word list 1-grams. next word probability probability next word given previous n-1 words. calculated using Maximum Likelihood Estimation (MLE) described . Instead storing n-gram prefix strings, single number saved. Also instead storing next word, numeric index next word saved. saves lot memory allows data stored, improves n-gram model’s efficiency. R, number requires fixed amount storage, 56 bytes. contrast memory required store string increases number characters string. data frames represent transition probability table combined single data frame. combined transition probability table used make word predictions.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"using-the-model-to-predict-words","dir":"Articles","previous_headings":"","what":"Using the model to predict words","title":"Overview","text":"predict word, word along n-1 previous words used input. model computes hash previous words looks hash combined transition probabilities table. hash found, model extracts top 3 next word ids highest probabilities. model looks next word text corresponds next word ids. result top 3 likely next words along probabilities. hash found, hash n-2 previous words calculated looked combined transition probabilities table. process repeated previous words. happens, model returns “word found” message. method checking transition probabilities lower level n-grams called back-. alternate method predicting word use interpolation. involves weighing summing probabilities n-gram size.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"predicting-the-model-performance","dir":"Articles","previous_headings":"","what":"Predicting the model performance","title":"Overview","text":"wordpredictor package provides methods performing intrinsic extrinsic evaluation n-gram model. wordpredictor package performs intrinsic evaluation calculating mean Perplexity score sentences validation text file. Perplexity sentence calculated taking N-th root inverse product probabilities words sentence. N number words sentence. probability word calculated considering n-1 words word. word found transition probabilities table, n-2 words looked . process repeated previous words. word found 1-gram list, probability word calculated simply dividing number times word occurs total number words. word found 1-gram list, model uses default probability probability word. default probability calculated using Laplace Smoothing. Laplace Smoothing involves adding 1 frequency count word vocabulary. Essentially means total number words data set increased vc, vc number words vocabulary. Laplace Smoothing 1 added word count. Since unknown word occurs zero times, Laplace Smoothing count 1. default probability calculated : P(unk) = 1/(N+VC), N total number words data set VC number words vocabulary. default probability assigned unknown words. Alternative methods Laplace Smoothing Add-k smoothing, Kneser-Ney smoothing Good-Turing Smoothing. wordpredictor package uses file /usr/share/dict/cracklib-small dictionary file. file pre-installed Linux distributions. Extrinsic evaluation involves calculating accuracy score. model tries predict last word sentence. actual last word one 3 words predicted model, prediction considered accurate. accuracy score number sentences correctly predicted.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"generating-the-model","dir":"Articles","previous_headings":"","what":"Generating the model","title":"Overview","text":"ModelGenerator class allows generating final n-gram model using single method call. following example generates n-gram model using default data cleaning tokenization options:","code":"# The required files rf <- c(\"input.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The following code generates n-gram model using default options for data # cleaning and tokenization. See the following section on how to customize these # options. Note that input.txt is the name of the input data file. It should be # present in the ed directory. The generated model file is also placed in this # directory.  # ModelGenerator class object is created mg <- ModelGenerator$new(     name = \"def-model\",     desc = \"N-gram model generating using default options\",     fn = \"def-model.RDS\",     df = \"input.txt\",     n = 4,     ssize = 0.1,     dir = ed,     dc_opts = list(),     tg_opts = list(),     ve = ve )  # Generates n-gram model. The output is the file # ./data/model/def-model.RDS mg$generate_model()  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"evaluating-the-model-performance","dir":"Articles","previous_headings":"","what":"Evaluating the model performance","title":"Overview","text":"wordpredictor package provides ModelEvaluator class evaluating performance generated n-gram model. following example performs intrinsic evaluation. measures Perplexity score sentence validation.txt file. returns minimum, mean maximum Perplexity score line. following example performs extrinsic evaluation. measures accuracy score sentence validation.txt file. sentence model used predict last word sentence given previous words. last word correctly predicted, prediction considered accurate. extrinsic evaluation returns number correct incorrect predictions.","code":"# The required files rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The path to the cleaned validation file vfn <- paste0(ed, \"/validate-clean.txt\") # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed on first 20 lines stats <- me$intrinsic_evaluation(lc = 20, fn = vfn)  # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The path to the cleaned validation file vfn <- paste0(ed, \"/validate-clean.txt\") # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed on first 100 lines stats <- me$extrinsic_evaluation(lc = 100, fn = vfn)  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"how-to-predict-a-word","dir":"Articles","previous_headings":"","what":"How to predict a word","title":"Overview","text":"following example shows predict next word. returns 3 possible next words along probabilities.","code":"# The required files rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # An object of class ModelPredictor is created. The mf parameter is the name of # the model file that was generated in the previous example. mp <- ModelPredictor$new(mf = mfn, ve = ve) # Given the words: \"how are\", the next word is predicted. The top 3 most likely # next words are returned along with their respective probabilities. res <- mp$predict_word(words = \"how are\", 3) # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"demo","dir":"Articles","previous_headings":"","what":"Demo","title":"Overview","text":"wordpredictor package includes demo called “word-predictor.” demo Shiny application displays ten likely words given set words. access demo, run following command R shell: demo(\"word-predictor\", package = \"wordpredictor\", ask = F).","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"package-dependencies","dir":"Articles","previous_headings":"","what":"Package dependencies","title":"Overview","text":"wordpredictor package uses following packages: digest, dply, ggplot2, R6, testthat stingr following packages useful package development: quanteda, tm hash lintr styler pkgdown pryr,","code":""},{"path":"https://pakjiddat.github.io/word-predictor/articles/overview.html","id":"useful-links","dir":"Articles","previous_headings":"","what":"Useful Links","title":"Overview","text":"following articles tutorials useful: N-Gram Model Probability Smoothing Natural Language Processing Natural Language Processing Fun! Quanteda Tutorials","code":""},{"path":[]},{"path":"https://pakjiddat.github.io/word-predictor/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Nadir Latif. Author, maintainer.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Latif N (2021). Develop Text Prediction Models Based N-Grams. R package version 1.0.0, https://github.com/pakjiddat/word-predictor.","code":"@Manual{,   title = {Develop Text Prediction Models Based on N-Grams},   author = {Nadir Latif},   year = {2021},   note = {R package version 1.0.0},   url = {https://github.com/pakjiddat/word-predictor}, }"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"introduction","dir":"","previous_headings":"","what":"Develop Text Prediction Models Based on N-Grams","title":"Develop Text Prediction Models Based on N-Grams","text":"goal wordpredictor package provide flexible easy use framework generating n-gram models word prediction. package allows generating n-gram models input text files. also allows exploring n-grams using plots. Additionally provides methods measuring n-gram model performance using Perplexity accuracy. n-gram model may customized using several options n-gram size, data cleaning options options tokenization.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"installation","dir":"","previous_headings":"","what":"Installation","title":"Develop Text Prediction Models Based on N-Grams","text":"can install released version wordpredictor CRAN : development version GitHub :","code":"install.packages(\"wordpredictor\") # install.packages(\"devtools\") devtools::install_github(\"pakjiddat/word-predictor\")"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"package-structure","dir":"","previous_headings":"","what":"Package structure","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor package based R6 classes. easy customize improve. provides following classes: DataAnalyzer. allows analyzing n-grams. DataCleaner. allows cleaning text files. supports several data cleaning options. DataSampler. allows generating sample files specified size text file. also allows generating train, test validation sample files given input text file. TokenGenerator. allows generating n-gram tokens given size. TPGenerator. allows generating transition probabilities given n-gram file. ModelGenerator. allows generating n-gram models using different configuration options. ModelEvaluator. allows evaluating performance n-gram models. 4 metrics used compare performance. : Perplexity, accuracy, memory time taken. ModelPredictor. allows predicting next word, given set previous words. Base. base class classes. allows provides methods reading writing files processing large text files. Information package can obtained using command line package website. example, command: ?wordpredictor returns information given class works parameter details class method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"generating-the-model","dir":"","previous_headings":"","what":"Generating the model","title":"Develop Text Prediction Models Based on N-Grams","text":"following example shows generate n-gram model. code generates file def-model.RDS. file represents n-gram model.","code":"# The required files rf <- c(\"input.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The following code generates n-gram model using default options for data # cleaning and tokenization. See the following section on how to customize these # options. Note that input.txt is the name of the input data file. It should be # present in the data directory. ddir is the data directory. mdir is the model # directory. The output model file, which is def-model.RDS will be placed in # this directory.  # ModelGenerator class object is created mg <- ModelGenerator$new(     name = \"def-model\",     desc = \"N-gram model generating using default options\",     fn = \"def-model.RDS\",     df = \"input.txt\",     n = 4,     ssize = 10,     dir = ed,     dc_opts = list(),     tg_opts = list(),     ve = ve )  # Generates n-gram model. The output is the file def-model.RDS mg$generate_model()  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"predicting-words","dir":"","previous_headings":"","what":"Predicting words","title":"Develop Text Prediction Models Based on N-Grams","text":"following example shows predict next word given set words:","code":"# The required files rf <- c(\"def-model.RDS\") # The test environment is setup ed <- setup_env(rf, ve) #>  [1] \"CITATION\"    \"demo\"        \"DESCRIPTION\" \"examples\"    \"extdata\"     #>  [6] \"help\"        \"html\"        \"INDEX\"       \"LICENSE\"     \"Meta\"        #> [11] \"NAMESPACE\"   \"NEWS.md\"     \"R\"  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # An object of class ModelPredictor is created. The mf parameter is the name of # the model file that was generated in the previous example. mp <- ModelPredictor$new(mf = mfn) # Given the words: \"how are\", the next word is predicted. The top 3 most likely # next words are returned along with their respective probabilities. res <- mp$predict_word(words = \"how are\", 3)  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"analyzing-n-grams","dir":"","previous_headings":"","what":"Analyzing N-grams","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor package includes class called DataAnalyzer, can used get idea frequency distribution n-grams model. model generation process described , creates n-gram file model directory. n-gram number less equal n-gram size model, n-gram file generated. example n-gram size model 4. 4 n-gram files generated model folder. files : n1.RDS, n2.RDS, n3.RDS n4.RDS. n2.RDS file contains n-grams size 2. following example plots top 10 occurring bi-grams along frequencies:  following example plots n-gram frequency coverage. shows percentage n-grams frequency 1, 2 … 10.  following example shows get list bi-grams starting “great_” along frequencies. also shows get frequency bi-gram “great_deal”.","code":"# The required files rf <- c(\"n2.RDS\") # The test environment is setup ed <- setup_env(rf, ve) #>  [1] \"CITATION\"    \"demo\"        \"DESCRIPTION\" \"examples\"    \"extdata\"     #>  [6] \"help\"        \"html\"        \"INDEX\"       \"LICENSE\"     \"Meta\"        #> [11] \"NAMESPACE\"   \"NEWS.md\"     \"R\"  # The file name fn <- paste0(ed, \"/n2.RDS\") # An object of class DataAnalyzer is created. The fn parameter is the path to # the n-gram file. da <- DataAnalyzer$new(fn = fn) # The top 10 most occurring features are plotted df <- da$plot_n_gram_stats(opts = list(   \"type\" = \"top_features\",   \"n\" = 10,   \"save_to\" = NULL,   \"dir\" = NULL )) # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"n2.RDS\") # The test environment is setup ed <- setup_env(rf, ve) #>  [1] \"CITATION\"    \"demo\"        \"DESCRIPTION\" \"examples\"    \"extdata\"     #>  [6] \"help\"        \"html\"        \"INDEX\"       \"LICENSE\"     \"Meta\"        #> [11] \"NAMESPACE\"   \"NEWS.md\"     \"R\"  # The file name fn <- paste0(ed, \"/n2.RDS\") # An object of class DataAnalyzer is created. The fn parameter is the path to # the n-gram file. da <- DataAnalyzer$new(fn = fn) # The top 10 most occurring features are plotted df <- da$plot_n_gram_stats(opts = list(   \"type\" = \"coverage\",   \"n\" = 10,   \"save_to\" = NULL,   \"dir\" = NULL )) # The test environment is cleaned up clean_up(ve) # The required files rf <- c(\"n2.RDS\") # The test environment is setup ed <- setup_env(rf, ve) #>  [1] \"CITATION\"    \"demo\"        \"DESCRIPTION\" \"examples\"    \"extdata\"     #>  [6] \"help\"        \"html\"        \"INDEX\"       \"LICENSE\"     \"Meta\"        #> [11] \"NAMESPACE\"   \"NEWS.md\"     \"R\"  # The file name fn <- paste0(ed, \"/n2.RDS\") # An object of class DataAnalyzer is created. The fn parameter is the path to # the n-gram file. da <- DataAnalyzer$new() # Bi-grams starting with \"great_\" are returned df <- da$get_ngrams(fn = fn, c = 10, pre = \"^great_*\") # The data frame is sorted by frequency df <- df[order(df$freq, decreasing = T),] # The frequency of the bi-gram \"great_deal\" f <- as.numeric(df[df$pre == \"great_deal\", \"freq\"])  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"customizing-the-n-gram-model","dir":"","previous_headings":"","what":"Customizing the n-gram model","title":"Develop Text Prediction Models Based on N-Grams","text":"dc_opts parameter ModelGenerator class specifies data cleaning options. following code shows data cleaning options default values: tg_opts parameter ModelGenerator class specifies token generation options. following code shows token generation options default values:","code":"# @field dc_opts The options for the data cleaner object. #   min_words -> The minimum number of words per sentence. #   line_count -> The number of lines to read and clean at a time. #   save_data -> If the combined processed lines should be saved. #   output_file -> Name of the output file used to store the data. #   sw_file -> The stop words file path. #   dict_file -> The dictionary file path. #   bad_file -> The bad words file path. #   to_lower -> If the words should be converted to lower case. #   remove_stop -> If stop words should be removed. #   remove_punct -> If punctuation symbols should be removed. #   remove_non_dict -> If non dictionary words should be removed. #   remove_non_alpha -> If non alphabet symbols should be removed. #   remove_extra_space -> If leading, trailing and double spaces #     should be removed. #   remove_bad -> If bad words should be removed dc_opts = list(   \"min_words\" = 2,   \"line_count\" = 1000,   \"save_data\" = T,   \"output_file\" = NULL,   \"sw_file\" = NULL,   \"dict_file\" = NULL,   \"bad_file\" = NULL,   \"to_lower\" = T,   \"remove_stop\" = F,   \"remove_punct\" = T,   \"remove_non_dict\" = T,   \"remove_non_alpha\" = T,   \"remove_extra_space\" = T,   \"remove_bad\" = F ) # @field tg_opts The options for the token generator obj. #   min_freq -> All ngrams with frequency less than min_freq are #     ignored. #   stem_words -> If words should be transformed to their stems. tg_opts = list(   \"stem_words\" = F,   \"min_freq\" = -1 )"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"evaluating-model-performance","dir":"","previous_headings":"","what":"Evaluating model performance","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor package allows evaluating n-gram model performance. can measure performance single model well compare performance multiple models. evaluating performance model, intrinsic extrinsic evaluation performed. Intrinsic evaluation measures Perplexity score sentence validation text file. returns minimum, maximum mean Perplexity score sentences. Extrinsic evaluation measures accuracy score sentences validation text file. tries predict last word sentence. word correctly predicted, accuracy count increased. extrinsic evaluation returns number valid invalid predictions. following example shows evaluate performance model:","code":"# The required files rf <- c(\"def-model.RDS\", \"validate.txt\") # The test environment is setup ed <- setup_env(rf, ve)  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate.txt\") # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = 2) # The performance evaluation is performed. The performance stats are returned as # a data frame and also saved within the model file itself. stats <- me$evaluate_performance(lc = 20, fn = vfn)  # The test environment is cleaned up clean_up(ve)"},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"demo","dir":"","previous_headings":"","what":"Demo","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor package includes demo called “word-predictor”. demo Shiny application displays ten likely words given set words. access demo, run following command R shell: demo(\"word-predictor\", package = \"wordpredictor\", ask = F). following screenshot demo:","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"website","dir":"","previous_headings":"","what":"Website","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor website provides details package works. includes code samples details classes methods.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"benefits","dir":"","previous_headings":"","what":"Benefits","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor package provides easy use framework working n-gram models. allows n-gram model generation, performance evaluation word prediction.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"limitations","dir":"","previous_headings":"","what":"Limitations","title":"Develop Text Prediction Models Based on N-Grams","text":"n-gram language model requires lot memory storing n-grams. wordpredictor package tested machine dual core processor 4 GB RAM. works well input data files size less 40 Mb n-gram size 4. larger data files n-gram size, memory CPU power needed.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"future-work","dir":"","previous_headings":"","what":"Future Work","title":"Develop Text Prediction Models Based on N-Grams","text":"wordpredictor package may extended adding support different smoothing techniques Good-Turing, Katz-Back-handling Vocabulary Words. Support different types n-gram models Skip-Grams Syntatic n-grams. wordpredictor package used predicting words. may extended support use cases spelling correction, biological sequence analysis, data compression . require performance optimization. source code organized using R6 classes. easy extend. Contributions welcome !.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/index.html","id":"acknowledgments","dir":"","previous_headings":"","what":"Acknowledgments","title":"Develop Text Prediction Models Based on N-Grams","text":"motivated develop wordpredictor package taking courses Data Science Specialization offered John Hopkins university Coursera. like thank course instructors making courses interesting motivating students.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":null,"dir":"Reference","previous_headings":"","what":"Base class for all other classes — Base","title":"Base class for all other classes — Base","text":"Provides basic structure processing text files. Also provides methods reading writing files objects.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Base class for all other classes — Base","text":"provides pre-processing, processing post-processing methods, need overridden derived classes. pre-processing function called reading file. process function called processing given number lines. post processing function called processed data. Also provides methods reading writing text files R objects. class methods private.","code":""},{"path":[]},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Base class for all other classes — Base","text":"Base$new() Base$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Base class for all other classes — Base","text":"initializes current object. used set file name verbose options.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Base class for all other classes — Base","text":"","code":"Base$new(fn = NULL, lc = 100, ve = 2)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base class for all other classes — Base","text":"fn path file clean. lc number lines read clean time. ve level detail information messages. Reads given file one line time. runs given pre-processing function reading file. runs given","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Base class for all other classes — Base","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Base class for all other classes — Base","text":"","code":"Base$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Base.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Base class for all other classes — Base","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":null,"dir":"Reference","previous_headings":"","what":"Analyzes input text files and n-gram token files — DataAnalyzer","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"provides method returns information text files, number lines number words. also provides method displays bar plots n-gram frequencies. Additionally provides method searching n-grams n-gram token file. file generated using TokenGenerator class.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"provides method returns text file information. text file information includes total number lines, max, min mean line length file size. also provides method generates bar plot showing common n-gram tokens. Another method provided returns list n-grams match given regular expression.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"wordpredictor::Base -> DataAnalyzer","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"DataAnalyzer$new() DataAnalyzer$plot_n_gram_stats() DataAnalyzer$get_file_info() DataAnalyzer$get_ngrams() DataAnalyzer$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"initializes current object. used set file name verbose options.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"DataAnalyzer$new(fn = NULL, ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"fn path input file. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"method-plot-n-gram-stats-","dir":"Reference","previous_headings":"","what":"Method plot_n_gram_stats()","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"allows generating two type n-gram plots. first reads n-gram token frequencies input text file. n-gram frequencies displayed bar plot. type plot specified type option. type options can values 'top_features' 'coverage'. 'top_features' displays top n occurring tokens along frequencies. 'coverage' displays number words along frequencies. plot stats returned data frame.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"DataAnalyzer$plot_n_gram_stats(opts)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"opts options analyzing data. type. type plot display. options : 'top_features', 'coverage'. n. 'top_features', number top occurring tokens. 'coverage' first n frequencies. save_to. graphics devices save plot . NULL implies plot printed. dir. output directory plot saved.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"data frame containing stats.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL value implies tempdir will # be used. fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"n2.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The n-gram file name nfn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(nfn, ve = ve) # The top features plot is checked df <- da$plot_n_gram_stats(opts = list(     \"type\" = \"top_features\",     \"n\" = 10,     \"save_to\" = NULL,     \"dir\" = ed )) # N-gram statistics are displayed print(df) # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"method-get-file-info-","dir":"Reference","previous_headings":"","what":"Method get_file_info()","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"generates information text files. takes input file directory containing text files. file calculates total number lines, maximum, minimum mean line lengths total file size. file information returned data frame.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"DataAnalyzer$get_file_info(res)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"res name directory file name.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"data frame containing text file statistics.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"examples-1","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"test.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The test file name cfn <- paste0(ed, \"/test.txt\") # The DataAnalyzer object is created da <- DataAnalyzer$new(ve = ve) # The file info is fetched fi <- da$get_file_info(cfn) # The file information is printed print(fi)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"method-get-ngrams-","dir":"Reference","previous_headings":"","what":"Method get_ngrams()","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"extracts given number n-grams frequencies n-gram token file. prefix parameter specifies regular expression matching n-grams. parameter specified given number n-grams randomly chosen.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"DataAnalyzer$get_ngrams(fn, c = NULL, pre = NULL)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"fn n-gram file name. c number n-grams return. pre n-gram prefix, given regular expression.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"examples-2","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"n2.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The n-gram file name nfn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(nfn, ve = ve) # Bi-grams starting with \"and_\" are returned df <- da$get_ngrams(fn = nfn, c = 10, pre = \"^and_*\") # The data frame is sorted by frequency df <- df[order(df$freq, decreasing = TRUE),] # The data frame is printed print(df)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"DataAnalyzer$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataAnalyzer.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Analyzes input text files and n-gram token files — DataAnalyzer","text":"","code":"## ------------------------------------------------ ## Method `DataAnalyzer$plot_n_gram_stats` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL value implies tempdir will # be used. fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"n2.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The n-gram file name nfn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(nfn, ve = ve) # The top features plot is checked df <- da$plot_n_gram_stats(opts = list(     \"type\" = \"top_features\",     \"n\" = 10,     \"save_to\" = NULL,     \"dir\" = ed ))  # N-gram statistics are displayed print(df) #> # A tibble: 10 × 2 #>    pre          freq #>    <chr>       <dbl> #>  1 in_the          4 #>  2 of_the          4 #>  3 on_the          4 #>  4 to_the          4 #>  5 from_the        3 #>  6 in_a            3 #>  7 a_thin          2 #>  8 and_the         2 #>  9 between_the     2 #> 10 down_the        2 # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `DataAnalyzer$get_file_info` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"test.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The test file name cfn <- paste0(ed, \"/test.txt\") # The DataAnalyzer object is created da <- DataAnalyzer$new(ve = ve) # The file info is fetched fi <- da$get_file_info(cfn) # The file information is printed print(fi) #> $file_stats #>                         fn total_lc max_ll min_ll mean_ll size #> 1 /tmp/RtmpcJbhpv/test.txt       73     51     28      41 3 Kb #>  #> $overall_stats #>   total_lc max_ll min_ll mean_ll total_s #> 1       73     51     28      41    3 Kb #>   # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `DataAnalyzer$get_ngrams` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"n2.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The n-gram file name nfn <- paste0(ed, \"/n2.RDS\") # The DataAnalyzer object is created da <- DataAnalyzer$new(nfn, ve = ve) # Bi-grams starting with \"and_\" are returned df <- da$get_ngrams(fn = nfn, c = 10, pre = \"^and_*\") # The data frame is sorted by frequency df <- df[order(df$freq, decreasing = TRUE),] # The data frame is printed print(df) #> # A tibble: 15 × 2 #>    pre         freq #>    <fct>      <dbl> #>  1 and_the        2 #>  2 and_cart       1 #>  3 and_fired      1 #>  4 and_forget     1 #>  5 and_leave      1 #>  6 and_open       1 #>  7 and_out        1 #>  8 and_phrase     1 #>  9 and_say        1 #> 10 and_tea        1 #> 11 and_tell       1 #> 12 and_then       1 #> 13 and_threw      1 #> 14 and_was        1 #> 15 and_watch      1  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":null,"dir":"Reference","previous_headings":"","what":"Provides data cleaning functionality — DataCleaner","title":"Provides data cleaning functionality — DataCleaner","text":"provides memory efficient method removing unneeded characters text files. suitable cleaning large text files.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Provides data cleaning functionality — DataCleaner","text":"provides method cleaning text files. allows removing bad words, stop words, non dictionary words, extra space, punctuation non-alphabet characters. also allows conversion lower case. supports large text files.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Provides data cleaning functionality — DataCleaner","text":"wordpredictor::Base -> DataCleaner","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Provides data cleaning functionality — DataCleaner","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Provides data cleaning functionality — DataCleaner","text":"DataCleaner$new() DataCleaner$clean_file() DataCleaner$clean_lines() DataCleaner$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Provides data cleaning functionality — DataCleaner","text":"initializes current object. used set file name verbose options.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"DataCleaner$new(fn = NULL, opts = list(), ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provides data cleaning functionality — DataCleaner","text":"fn path file clean. opts options data cleaning. min_words. minimum number words per sentence. line_count. number lines read clean time. save_data. combined processed lines saved. output_file. Name output file used store data. sw_file. stop words file path. dict_file. dictionary file path. bad_file. bad words file path. to_lower. words converted lower case. remove_stop. stop words removed. remove_punct. punctuation symbols removed. remove_non_dict. non dictionary words removed. remove_non_alpha. -> non alphabet symbols removed. remove_extra_space. -> leading, trailing double spaces removed. remove_bad. bad words removed ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"method-clean-file-","dir":"Reference","previous_headings":"","what":"Method clean_file()","title":"Provides data cleaning functionality — DataCleaner","text":"provides efficient method cleaning text files. removes unneeded characters given text file several options. allows removing punctuation, bad words, stop words, non-alphabetical symbols non-dictionary words. reads certain number lines given text file. removes unneeded characters lines saves lines output text file. File cleaning progress displayed verbose option set class constructor. suitable cleaning large text files.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"DataCleaner$clean_file()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"test.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The cleaned test file name cfn <- paste0(ed, \"/test-clean.txt\") # The test file name fn <- paste0(ed, \"/test.txt\") # The data cleaning options dc_opts <- list(\"output_file\" = cfn) # The data cleaner object is created dc <- DataCleaner$new(fn, dc_opts, ve = ve) # The sample file is cleaned dc$clean_file()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"method-clean-lines-","dir":"Reference","previous_headings":"","what":"Method clean_lines()","title":"Provides data cleaning functionality — DataCleaner","text":"cleans given lines text using options passed current object.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"DataCleaner$clean_lines(lines)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provides data cleaning functionality — DataCleaner","text":"lines input sentences.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Provides data cleaning functionality — DataCleaner","text":"cleaned lines text.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"examples-1","dir":"Reference","previous_headings":"","what":"Examples","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"# The level of detail in the information messages ve <- 0 # Test data is read l <- c(     \"If you think I'm wrong, send me a link to where it's happened\",     \"We're about 90percent done with this room\",     \"This isn't how I wanted it between us.\",     \"Almost any cute breed can become ornamental\",     \"Once upon a time there was a kingdom with a castle\",     \"That's not a thing any of us are granted'\",     \"Why are you being so difficult? she asks.\" ) # The expected results res <- c(     \"if you think wrong send me a link to where its happened\",     \"were about percent done with this room\",     \"this how i wanted it between us\",     \"almost any cute breed can become ornamental\",     \"once upon a time there was a kingdom with a castle\",     \"thats not a thing any of us are granted\",     \"why are you being so difficult she asks\" ) # The DataCleaner object is created dc <- DataCleaner$new(ve = ve) # The line is cleaned cl <- dc$clean_lines(l) # The cleaned lines are printed print(cl)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Provides data cleaning functionality — DataCleaner","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"DataCleaner$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Provides data cleaning functionality — DataCleaner","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataCleaner.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Provides data cleaning functionality — DataCleaner","text":"","code":"## ------------------------------------------------ ## Method `DataCleaner$clean_file` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"test.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The cleaned test file name cfn <- paste0(ed, \"/test-clean.txt\") # The test file name fn <- paste0(ed, \"/test.txt\") # The data cleaning options dc_opts <- list(\"output_file\" = cfn) # The data cleaner object is created dc <- DataCleaner$new(fn, dc_opts, ve = ve) # The sample file is cleaned dc$clean_file()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `DataCleaner$clean_lines` ## ------------------------------------------------  # The level of detail in the information messages ve <- 0 # Test data is read l <- c(     \"If you think I'm wrong, send me a link to where it's happened\",     \"We're about 90percent done with this room\",     \"This isn't how I wanted it between us.\",     \"Almost any cute breed can become ornamental\",     \"Once upon a time there was a kingdom with a castle\",     \"That's not a thing any of us are granted'\",     \"Why are you being so difficult? she asks.\" ) # The expected results res <- c(     \"if you think wrong send me a link to where its happened\",     \"were about percent done with this room\",     \"this how i wanted it between us\",     \"almost any cute breed can become ornamental\",     \"once upon a time there was a kingdom with a castle\",     \"thats not a thing any of us are granted\",     \"why are you being so difficult she asks\" ) # The DataCleaner object is created dc <- DataCleaner$new(ve = ve) # The line is cleaned cl <- dc$clean_lines(l) # The cleaned lines are printed print(cl) #> [1] \"if you think wrong send me a link to where its happened\" #> [2] \"were about percent done with this room\"                  #> [3] \"this how i wanted it between us\"                         #> [4] \"almost any cute breed can become ornamental\"             #> [5] \"once upon a time there was a kingdom with a castle\"      #> [6] \"thats not a thing any of us are granted\"                 #> [7] \"why are you being so difficult she asks\""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates data samples from text files — DataSampler","title":"Generates data samples from text files — DataSampler","text":"provides method generating training, testing validation data sets given input text file. also provides method generating sample file given size number lines input text file. contents sample file may cleaned randomized.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Generates data samples from text files — DataSampler","text":"wordpredictor::Base -> DataSampler","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Generates data samples from text files — DataSampler","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Generates data samples from text files — DataSampler","text":"DataSampler$new() DataSampler$generate_sample() DataSampler$generate_data() DataSampler$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Generates data samples from text files — DataSampler","text":"initializes current object. used set verbose option.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates data samples from text files — DataSampler","text":"","code":"DataSampler$new(dir = \".\", ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates data samples from text files — DataSampler","text":"dir directory storing input output files. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"method-generate-sample-","dir":"Reference","previous_headings":"","what":"Method generate_sample()","title":"Generates data samples from text files — DataSampler","text":"Generates sample file given size given input file. file saved directory given dir object attribute. file generated, contents may cleaned randomized.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates data samples from text files — DataSampler","text":"","code":"DataSampler$generate_sample(fn, ss, ic, ir, ofn, is, dc_opts = NULL)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates data samples from text files — DataSampler","text":"fn input file name. short file name relative dir attribute. ss number lines proportion lines sample. ic sample file cleaned. ir sample file contents randomized. ofn output file name. saved dir. sampled data saved file. dc_opts options cleaning data.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates data samples from text files — DataSampler","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"input.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The sample file name sfn <- paste0(ed, \"/sample.txt\") # An object of class DataSampler is created ds <- DataSampler$new(dir = ed, ve = ve) # The sample file is generated ds$generate_sample(     fn = \"input.txt\",     ss = 0.5,     ic = FALSE,     ir = FALSE,     ofn = \"sample.txt\",     is = TRUE )  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"method-generate-data-","dir":"Reference","previous_headings":"","what":"Method generate_data()","title":"Generates data samples from text files — DataSampler","text":"generates training, testing validation data sets given input file. first reads file given parameter current object. partitions data training, testing validation sets, according perc parameter. files named train.txt, test.txt va.txt saved given output folder.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates data samples from text files — DataSampler","text":"","code":"DataSampler$generate_data(fn, percs)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates data samples from text files — DataSampler","text":"fn input file name. relative dir attribute. percs size training, testing validation sets.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"examples-1","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates data samples from text files — DataSampler","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be # used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"input.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve) # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The files to clean fns <- c(\"train\", \"test\", \"validate\") # An object of class DataSampler is created ds <- DataSampler$new(dir = ed, ve = ve) # The train, test and validation files are generated ds$generate_data(     fn = \"input.txt\",     percs = list(         \"train\" = 0.8,         \"test\" = 0.1,         \"validate\" = 0.1     ) )  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Generates data samples from text files — DataSampler","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates data samples from text files — DataSampler","text":"","code":"DataSampler$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates data samples from text files — DataSampler","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/DataSampler.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates data samples from text files — DataSampler","text":"","code":"## ------------------------------------------------ ## Method `DataSampler$generate_sample` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"input.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The sample file name sfn <- paste0(ed, \"/sample.txt\") # An object of class DataSampler is created ds <- DataSampler$new(dir = ed, ve = ve) # The sample file is generated ds$generate_sample(     fn = \"input.txt\",     ss = 0.5,     ic = FALSE,     ir = FALSE,     ofn = \"sample.txt\",     is = TRUE )  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `DataSampler$generate_data` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be # used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"input.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve) # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The files to clean fns <- c(\"train\", \"test\", \"validate\") # An object of class DataSampler is created ds <- DataSampler$new(dir = ed, ve = ve) # The train, test and validation files are generated ds$generate_data(     fn = \"input.txt\",     percs = list(         \"train\" = 0.8,         \"test\" = 0.1,         \"validate\" = 0.1     ) )  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":null,"dir":"Reference","previous_headings":"","what":"Allows managing the test environment — EnvManager","title":"Allows managing the test environment — EnvManager","text":"class provides method creating directories tempdir folder testing purposes. also provides method reading files inst/extdata folder.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Allows managing the test environment — EnvManager","text":"wordpredictor::Base -> EnvManager","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Allows managing the test environment — EnvManager","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Allows managing the test environment — EnvManager","text":"EnvManager$new() EnvManager$get_data_fn() EnvManager$remove_files() EnvManager$td_env() EnvManager$cp_env() EnvManager$setup_env() EnvManager$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Allows managing the test environment — EnvManager","text":"initializes current object. simply calls base class constructor.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$new(rp = \"../../\", ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows managing the test environment — EnvManager","text":"rp prefix accessing package root folder. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-get-data-fn-","dir":"Reference","previous_headings":"","what":"Method get_data_fn()","title":"Allows managing the test environment — EnvManager","text":"Checks given file exists. exist, tries load file inst/extdata data folder package. throws error file found. file exists, method simply returns file name.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$get_data_fn(fn, dfn)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows managing the test environment — EnvManager","text":"fn file name. dfn name default file external data folder package.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Allows managing the test environment — EnvManager","text":"name file exists, full path default file.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-remove-files-","dir":"Reference","previous_headings":"","what":"Method remove_files()","title":"Allows managing the test environment — EnvManager","text":"Removes files given directory.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$remove_files(dn)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows managing the test environment — EnvManager","text":"dn directory name.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-td-env-","dir":"Reference","previous_headings":"","what":"Method td_env()","title":"Allows managing the test environment — EnvManager","text":"Removes ed folder created setup_env method. Also sets R option, \"ed\" NULL.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$td_env(rf = F)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows managing the test environment — EnvManager","text":"rf environment folder removed.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-cp-env-","dir":"Reference","previous_headings":"","what":"Method cp_env()","title":"Allows managing the test environment — EnvManager","text":"Copies ed folder created setup_env method inst/extdata.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$cp_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-setup-env-","dir":"Reference","previous_headings":"","what":"Method setup_env()","title":"Allows managing the test environment — EnvManager","text":"Copies given files test folder environment folder.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$setup_env(fns = c(), cf = NULL)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows managing the test environment — EnvManager","text":"fns list test files copy cf custom environment folder. path relative current directory. specified, tempdir function used generate environment folder.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Allows managing the test environment — EnvManager","text":"list folders can used testing.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Allows managing the test environment — EnvManager","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows managing the test environment — EnvManager","text":"","code":"EnvManager$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/EnvManager.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows managing the test environment — EnvManager","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":null,"dir":"Reference","previous_headings":"","what":"Represents n-gram models — Model","title":"Represents n-gram models — Model","text":"Model class represents n-gram models. instance class single n-gram model. attributes class used store n-gram model information. class provides methods loading saving model.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Represents n-gram models — Model","text":"attributes class used store n-gram model information model name, model description, model file name, n-gram size, transition probabilities data, default probability words, data cleaning tokenization options, word list, model path, data directory path performance stats. model saved single file R object. model file contains information required model. model object used input classes perform operations model evaluation model performance, text predictions comparison model performance.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Represents n-gram models — Model","text":"wordpredictor::Base -> Model","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Represents n-gram models — Model","text":"pstats performance stats model. name model name. desc model description.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Represents n-gram models — Model","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Represents n-gram models — Model","text":"Model$new() Model$load_model() Model$get_config() Model$get_size() Model$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Represents n-gram models — Model","text":"initializes current object. used set maximum n-gram number, sample size, input file name, data cleaner options, tokenization options, combined transition probabilities file name verbose.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Represents n-gram models — Model","text":"","code":"Model$new(   name = NULL,   desc = NULL,   fn = NULL,   df = NULL,   n = 4,   ssize = 0.3,   dir = \".\",   dc_opts = list(),   tg_opts = list(),   ve = 0 )"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Represents n-gram models — Model","text":"name model name. desc model description. fn model file name. df name file used generate model. n maximum n-gram number supported model. ssize sample size proportion input file. dir directory containing model files. dc_opts data cleaner options. tg_opts token generator options. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"method-load-model-","dir":"Reference","previous_headings":"","what":"Method load_model()","title":"Represents n-gram models — Model","text":"loads model using given information","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Represents n-gram models — Model","text":"","code":"Model$load_model()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"method-get-config-","dir":"Reference","previous_headings":"","what":"Method get_config()","title":"Represents n-gram models — Model","text":"returns given configuration data","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Represents n-gram models — Model","text":"","code":"Model$get_config(cn)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Represents n-gram models — Model","text":"cn name required configuration.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Represents n-gram models — Model","text":"configuration value.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"method-get-size-","dir":"Reference","previous_headings":"","what":"Method get_size()","title":"Represents n-gram models — Model","text":"returns size current object. object size calculated sum sizes object attributes.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Represents n-gram models — Model","text":"","code":"Model$get_size()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Represents n-gram models — Model","text":"size object bytes.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Represents n-gram models — Model","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Represents n-gram models — Model","text":"","code":"Model$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/Model.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Represents n-gram models — Model","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":null,"dir":"Reference","previous_headings":"","what":"Evaluates performance of n-gram models — ModelEvaluator","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"provides methods performing extrinsic intrinsic evaluation n-gram model. also provides method comparing performance multiple n-gram models. Intrinsic evaluation based calculation Perplexity. Extrinsic evaluation involves determining percentage correct next word predictions.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"performing intrinsic extrinsic model evaluation, validation file must first generated. can done using DataSampler class. line validation file evaluated. intrinsic evaluation Perplexity line calculated. overall summary Perplexity calculations returned. includes min, max mean Perplexity. extrinsic evaluation, next word prediction performed line. actual next word one three predicted next words, prediction considered accurate. extrinsic evaluation returns percentage correct incorrect predictions.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"wordpredictor::Base -> ModelEvaluator","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"ModelEvaluator$new() ModelEvaluator$compare_performance() ModelEvaluator$plot_stats() ModelEvaluator$evaluate_performance() ModelEvaluator$intrinsic_evaluation() ModelEvaluator$extrinsic_evaluation() ModelEvaluator$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"initializes current object. used set model file name verbose options.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$new(mf = NULL, ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"mf model file name. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-compare-performance-","dir":"Reference","previous_headings":"","what":"Method compare_performance()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"compares performance models given folder. performance model compared 4 metric time taken, memory used, Perplexity accuracy. performance comparison displayed plots. 4 plots displayed. One performance metric. fifth plot shows variation Perplexity accuracy. 5 plots plotted one page.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$compare_performance(opts)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"opts options comparing model performance. save_to. graphics device save plot . NULL implies plot printed. dir. directory containing model file, plot stats.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be # used. fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code # ModelEvaluator class object is created me <- ModelEvaluator$new(ve = ve) # The performance evaluation is performed me$compare_performance(opts = list(     \"save_to\" = NULL,     \"dir\" = ed ))  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-plot-stats-","dir":"Reference","previous_headings":"","what":"Method plot_stats()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"plots given stats 5 plots. plots displayed single page. 4 performance metrics time taken, memory, Perplexity accuracy plotted model name. Another plot compares Perplexity accuracy model.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$plot_stats(data)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"data data plot","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"ggplot object returned.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-evaluate-performance-","dir":"Reference","previous_headings":"","what":"Method evaluate_performance()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"performs intrinsic extrinsic evaluation given model validation text file. given number lines validation file used evaluation performs two types evaluations. One intrinsic evaluation, based Perplexity, extrinsic evaluation based accuracy. returns results evaluation. 4 evaluation metrics returned. Perplexity, accuracy, memory time taken. Memory size model object. Time taken time needed performing evaluations. results model evaluation saved within model object also returned.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$evaluate_performance(lc, fn)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"lc number lines text validation file used evaluation. fn name validation file. exist, default file validation-clean.txt checked models folder","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"performance stats returned.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"examples-1","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate-clean.txt\")  # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The performance evaluation is performed stats <- me$evaluate_performance(lc = 20, fn = vfn) # The evaluation stats are printed print(stats)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-intrinsic-evaluation-","dir":"Reference","previous_headings":"","what":"Method intrinsic_evaluation()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"Evaluates model using intrinsic evaluation based Perplexity. given number sentences taken validation file. sentence, Perplexity calculated.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$intrinsic_evaluation(lc, fn)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"lc number lines text validation file used evaluation. fn name validation file. exist, default file validation-clean.txt checked models folder","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"min, max mean Perplexity score.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"examples-2","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate-clean.txt\")  # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed stats <- me$intrinsic_evaluation(lc = 20, fn = vfn) # The evaluation stats are printed print(stats)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-extrinsic-evaluation-","dir":"Reference","previous_headings":"","what":"Method extrinsic_evaluation()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"Evaluates model using extrinsic evaluation based Accuracy. given number sentences taken validation file. sentence, model used predict next word. accuracy stats returned. prediction considered correct one predicted words matches actual word.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$extrinsic_evaluation(lc, fn)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments-5","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"lc number lines text validation file used evaluation. fn name validation file.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"returns-3","dir":"Reference","previous_headings":"","what":"Returns","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"number correct incorrect predictions.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"examples-3","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate-clean.txt\")  # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed stats <- me$extrinsic_evaluation(lc = 100, fn = vfn) # The evaluation stats are printed print(stats)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"usage-6","dir":"Reference","previous_headings":"","what":"Usage","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"ModelEvaluator$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"arguments-6","dir":"Reference","previous_headings":"","what":"Arguments","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelEvaluator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Evaluates performance of n-gram models — ModelEvaluator","text":"","code":"## ------------------------------------------------ ## Method `ModelEvaluator$compare_performance` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be # used. fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code # ModelEvaluator class object is created me <- ModelEvaluator$new(ve = ve) # The performance evaluation is performed me$compare_performance(opts = list(     \"save_to\" = NULL,     \"dir\" = ed ))   # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `ModelEvaluator$evaluate_performance` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate-clean.txt\")  # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The performance evaluation is performed stats <- me$evaluate_performance(lc = 20, fn = vfn) # The evaluation stats are printed print(stats) #> $m #> [1] 279320 #>  #> $t #> [1] 1.018 #>  #> $p #> [1] 2297.35 #>  #> $a #> [1] 0 #>   # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `ModelEvaluator$intrinsic_evaluation` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate-clean.txt\")  # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed stats <- me$intrinsic_evaluation(lc = 20, fn = vfn) # The evaluation stats are printed print(stats) #> $min #> [1] 282 #>  #> $max #> [1] 8248 #>  #> $mean #> [1] 2297.35 #>   # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `ModelEvaluator$extrinsic_evaluation` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\", \"validate-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # The validation file name vfn <- paste0(ed, \"/validate-clean.txt\")  # ModelEvaluator class object is created me <- ModelEvaluator$new(mf = mfn, ve = ve) # The intrinsic evaluation is performed stats <- me$extrinsic_evaluation(lc = 100, fn = vfn) # The evaluation stats are printed print(stats) #> $valid #> [1] 1 #>  #> $invalid #> [1] 74 #>  #> $valid_perc #> [1] 1.333333 #>  #> $invalid_perc #> [1] 98.66667 #>   # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates n-gram models from a text file — ModelGenerator","title":"Generates n-gram models from a text file — ModelGenerator","text":"provides method generating n-gram models. n-gram models may customized specifying data cleaning tokenization options.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates n-gram models from a text file — ModelGenerator","text":"provides method generates n-gram model. n-gram model may customized specifying data cleaning tokenization options. data cleaning options include removal punctuation, stop words, extra space, non-dictionary words bad words. tokenization options include n-gram number word stemming.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Generates n-gram models from a text file — ModelGenerator","text":"wordpredictor::Base -> ModelGenerator","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Generates n-gram models from a text file — ModelGenerator","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Generates n-gram models from a text file — ModelGenerator","text":"ModelGenerator$new() ModelGenerator$generate_model() ModelGenerator$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Generates n-gram models from a text file — ModelGenerator","text":"initializes current object. used set maximum n-gram number, sample size, input file name, data cleaner options, tokenization options verbose option.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates n-gram models from a text file — ModelGenerator","text":"","code":"ModelGenerator$new(   name = NULL,   desc = NULL,   fn = NULL,   df = NULL,   n = 4,   ssize = 0.3,   dir = \".\",   dc_opts = list(),   tg_opts = list(),   ve = 0 )"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates n-gram models from a text file — ModelGenerator","text":"name model name. desc model description. fn model file name. df path input text file. short file name present data directory. n n-gram size model. ssize sample size proportion input file. dir directory containing input output files. dc_opts data cleaner options. tg_opts token generator options. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"method-generate-model-","dir":"Reference","previous_headings":"","what":"Method generate_model()","title":"Generates n-gram models from a text file — ModelGenerator","text":"generates model using parameters passed object's constructor. generates n-gram model file saves model directory.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates n-gram models from a text file — ModelGenerator","text":"","code":"ModelGenerator$generate_model()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates n-gram models from a text file — ModelGenerator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"input.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # ModelGenerator class object is created mg <- ModelGenerator$new(     name = \"default-model\",     desc = \"1 MB size and default options\",     fn = \"def-model.RDS\",     df = \"input.txt\",     n = 4,     ssize = 0.99,     dir = ed,     dc_opts = list(),     tg_opts = list(),     ve = ve ) # The n-gram model is generated mg$generate_model()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Generates n-gram models from a text file — ModelGenerator","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates n-gram models from a text file — ModelGenerator","text":"","code":"ModelGenerator$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates n-gram models from a text file — ModelGenerator","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelGenerator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates n-gram models from a text file — ModelGenerator","text":"","code":"## ------------------------------------------------ ## Method `ModelGenerator$generate_model` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"input.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # ModelGenerator class object is created mg <- ModelGenerator$new(     name = \"default-model\",     desc = \"1 MB size and default options\",     fn = \"def-model.RDS\",     df = \"input.txt\",     n = 4,     ssize = 0.99,     dir = ed,     dc_opts = list(),     tg_opts = list(),     ve = ve ) # The n-gram model is generated mg$generate_model()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"provides method predicting new word given set previous words. also provides method calculating Perplexity score set words. Furthermore provides method calculating probability given word set previous words.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"wordpredictor::Base -> ModelPredictor","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"ModelPredictor$new() ModelPredictor$get_model() ModelPredictor$calc_perplexity() ModelPredictor$predict_word() ModelPredictor$get_word_prob() ModelPredictor$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"initializes current object. used set model file name verbose options.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"ModelPredictor$new(mf, ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"mf model file name. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"method-get-model-","dir":"Reference","previous_headings":"","what":"Method get_model()","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"Returns Model class object.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"ModelPredictor$get_model()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"Model class object returned.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"method-calc-perplexity-","dir":"Reference","previous_headings":"","what":"Method calc_perplexity()","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"Perplexity given sentence calculated. word, probability word given previous words calculated. probabilities multiplied inverted. nth root result perplexity, n number words sentence. stem_words tokenization option specified creating given model file, previous words converted stems.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"ModelPredictor$calc_perplexity(words)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"words list words.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"returns-1","dir":"Reference","previous_headings":"","what":"Returns","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"perplexity given list words.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # ModelPredictor class object is created mp <- ModelPredictor$new(mf = mfn, ve = ve) # The sentence whoose Perplexity is to be calculated l <- \"last year at this time i was preparing for a trip to rome\" # The line is split in to words w <- strsplit(l, \" \")[[1]] # The Perplexity of the sentence is calculated p <- mp$calc_perplexity(w) # The sentence Perplexity is printed print(p) # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"method-predict-word-","dir":"Reference","previous_headings":"","what":"Method predict_word()","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"Predicts next word given list previous words. checks last n previous words transition probabilities data, n equal 1 - n-gram size model. match, top 3 next words highest probabilities returned. match, last n-1 previous words checked. process continued last word checked. match, empty result returned. given words may optionally stemmed.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"ModelPredictor$predict_word(words, count = 3, dc = NULL)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"words character vector previous words single vector containing previous word text. count number results return. dc DataCleaner object. given, given words","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"returns-2","dir":"Reference","previous_headings":"","what":"Returns","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"top 3 predicted words along probabilities.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"examples-1","dir":"Reference","previous_headings":"","what":"Examples","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, \"rp\" = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # ModelPredictor class object is created mp <- ModelPredictor$new(mf = mfn, ve = ve) # The next word is predicted nws <- mp$predict_word(\"today is\", count = 10) # The predicted next words are printed print(nws)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"method-get-word-prob-","dir":"Reference","previous_headings":"","what":"Method get_word_prob()","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"Calculates probability given word given previous words. last n words converted numeric hash using digest2int function. words ignored. n equal 1 - size n-gram model. hash looked data frame transition probabilities. last word converted number checking position list unique words. hash word position found, probability previous word hash returned. found, hash n-1 previous words taken processed repeated. data found data frame, word probability returned. known back-. word probability found default probability returned. default probability calculated 1/(N+V), N = number words corpus V number dictionary words.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"usage-4","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"ModelPredictor$get_word_prob(word, pw)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"arguments-3","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"word word whose probability calculated. pw previous words.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"returns-3","dir":"Reference","previous_headings":"","what":"Returns","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"probability word given previous words.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"examples-2","dir":"Reference","previous_headings":"","what":"Examples","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, \"rp\" = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # ModelPredictor class object is created mp <- ModelPredictor$new(mf = mfn, ve = ve) # The probability that the next word is \"you\" given the prev words # \"how\" and \"are\" prob <- mp$get_word_prob(word = \"you\", pw = c(\"how\", \"are\")) # The probability is printed print(prob)  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"usage-5","dir":"Reference","previous_headings":"","what":"Usage","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"ModelPredictor$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"arguments-4","dir":"Reference","previous_headings":"","what":"Arguments","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/ModelPredictor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Allows predicting text, calculating word probabilities and Perplexity — ModelPredictor","text":"","code":"## ------------------------------------------------ ## Method `ModelPredictor$calc_perplexity` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # ModelPredictor class object is created mp <- ModelPredictor$new(mf = mfn, ve = ve) # The sentence whoose Perplexity is to be calculated l <- \"last year at this time i was preparing for a trip to rome\" # The line is split in to words w <- strsplit(l, \" \")[[1]] # The Perplexity of the sentence is calculated p <- mp$calc_perplexity(w) # The sentence Perplexity is printed print(p) #> [1] 1767 # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `ModelPredictor$predict_word` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, \"rp\" = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # ModelPredictor class object is created mp <- ModelPredictor$new(mf = mfn, ve = ve) # The next word is predicted nws <- mp$predict_word(\"today is\", count = 10) # The predicted next words are printed print(nws) #> $found #> [1] TRUE #>  #> $words #>  [1] \"a\"      \"the\"    \"used\"   \"better\" \"hard\"   \"rare\"   \"to\"     \"best\"   #>  [9] \"carved\" \"dry\"    #>  #> $probs #>  [1] 0.17460317 0.11111111 0.06349206 0.03174603 0.03174603 0.03174603 #>  [7] 0.03174603 0.01587302 0.01587302 0.01587302 #>   # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()  ## ------------------------------------------------ ## Method `ModelPredictor$get_word_prob` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"def-model.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, \"rp\" = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The model file name mfn <- paste0(ed, \"/def-model.RDS\") # ModelPredictor class object is created mp <- ModelPredictor$new(mf = mfn, ve = ve) # The probability that the next word is \"you\" given the prev words # \"how\" and \"are\" prob <- mp$get_word_prob(word = \"you\", pw = c(\"how\", \"are\")) # The probability is printed print(prob) #> [1] 0.0024581  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates transition probabilities for n-grams — TPGenerator","title":"Generates transition probabilities for n-grams — TPGenerator","text":"provides method generating transition probabilities given n-gram size. also provides method generating combined transition probabilities data n-gram sizes 1 given size. combined transition probabilities data can used implement back-.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Generates transition probabilities for n-grams — TPGenerator","text":"provides method generating n-gram transition probabilities. reads n-gram frequencies input text file generated TokenGenerator class. parses n-gram prefix, next word, next word frequency next word probability. Maximum Likelihood count used generate next word probabilities. n-gram prefix converted numeric hash using digest2int function. next word replaced position next word list words. transition probabilities data stored dataframe file. Another method provided combines transition probabilities n-grams size 1 given size. combined transition probabilities can saved file data frame. file may regarded completed self contained n-gram model. combining transition probabilities n-grams, back-may used evaluate word probabilities predict next word.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Generates transition probabilities for n-grams — TPGenerator","text":"wordpredictor::Base -> TPGenerator","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Generates transition probabilities for n-grams — TPGenerator","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Generates transition probabilities for n-grams — TPGenerator","text":"TPGenerator$new() TPGenerator$generate_tp() TPGenerator$generate_tp_for_n() TPGenerator$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Generates transition probabilities for n-grams — TPGenerator","text":"initializes current obj. used set transition probabilities options verbose option.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates transition probabilities for n-grams — TPGenerator","text":"","code":"TPGenerator$new(opts = list(), ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates transition probabilities for n-grams — TPGenerator","text":"opts options generating transition probabilities. save_tp. data saved. n. n-gram size. dir. directory containing input output files. format. format output. two options. plain. data stored plain text. obj. data stored R obj. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"method-generate-tp-","dir":"Reference","previous_headings":"","what":"Method generate_tp()","title":"Generates transition probabilities for n-grams — TPGenerator","text":"first generates transition probabilities n-gram size 1 given size. transition probabilities combined single data frame saved output folder given parameter current object. combining transition probabilities n-gram sizes 1 n, back-can used calculate next word probabilities predict next word.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates transition probabilities for n-grams — TPGenerator","text":"","code":"TPGenerator$generate_tp()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates transition probabilities for n-grams — TPGenerator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"n1.RDS\", \"n2.RDS\", \"n3.RDS\", \"n4.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The list of output files fns <- c(\"words\", \"model-4\", \"tp2\", \"tp3\", \"tp4\")  # The TPGenerator object is created tp <- TPGenerator$new(opts = list(n = 4, dir = ed), ve = ve) # The combined transition probabilities are generated tp$generate_tp()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"method-generate-tp-for-n-","dir":"Reference","previous_headings":"","what":"Method generate_tp_for_n()","title":"Generates transition probabilities for n-grams — TPGenerator","text":"generates transition probabilities table given n-gram size. first reads n-gram token frequencies input text file. generates data frame whose columns n-gram prefix, next word next word frequency. data frame may saved file plain text R obj. n = 1, list words saved.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates transition probabilities for n-grams — TPGenerator","text":"","code":"TPGenerator$generate_tp_for_n(n)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates transition probabilities for n-grams — TPGenerator","text":"n n-gram size tp data generated.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Generates transition probabilities for n-grams — TPGenerator","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"usage-3","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates transition probabilities for n-grams — TPGenerator","text":"","code":"TPGenerator$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"arguments-2","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates transition probabilities for n-grams — TPGenerator","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TPGenerator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates transition probabilities for n-grams — TPGenerator","text":"","code":"## ------------------------------------------------ ## Method `TPGenerator$generate_tp` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"n1.RDS\", \"n2.RDS\", \"n3.RDS\", \"n4.RDS\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The list of output files fns <- c(\"words\", \"model-4\", \"tp2\", \"tp3\", \"tp4\")  # The TPGenerator object is created tp <- TPGenerator$new(opts = list(n = 4, dir = ed), ve = ve) # The combined transition probabilities are generated tp$generate_tp()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":null,"dir":"Reference","previous_headings":"","what":"Generates n-grams from text files — TokenGenerator","title":"Generates n-grams from text files — TokenGenerator","text":"generates n-gram tokens along frequencies. data may saved file plain text format R object.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"super-class","dir":"Reference","previous_headings":"","what":"Super class","title":"Generates n-grams from text files — TokenGenerator","text":"wordpredictor::Base -> TokenGenerator","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"methods","dir":"Reference","previous_headings":"","what":"Methods","title":"Generates n-grams from text files — TokenGenerator","text":"Inherited methods","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Generates n-grams from text files — TokenGenerator","text":"TokenGenerator$new() TokenGenerator$generate_tokens() TokenGenerator$clone()","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"method-new-","dir":"Reference","previous_headings":"","what":"Method new()","title":"Generates n-grams from text files — TokenGenerator","text":"initializes current obj. used set file name, tokenization options verbose option.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates n-grams from text files — TokenGenerator","text":"","code":"TokenGenerator$new(fn = NULL, opts = list(), ve = 0)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates n-grams from text files — TokenGenerator","text":"fn path input file. opts options generating n-gram tokens. n. n-gram size. save_ngrams. n-gram data saved. min_freq. n-grams frequency less min_freq ignored. line_count. number lines process time. stem_words. words transformed stems. dir. dir output file saved. format. format output. two options. plain. data stored plain text. obj. data stored R obj. ve level detail information messages.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"method-generate-tokens-","dir":"Reference","previous_headings":"","what":"Method generate_tokens()","title":"Generates n-grams from text files — TokenGenerator","text":"generates n-gram tokens frequencies given file name. tokens may saved text file plain text R object.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates n-grams from text files — TokenGenerator","text":"","code":"TokenGenerator$generate_tokens()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Generates n-grams from text files — TokenGenerator","text":"data frame containing n-gram tokens along frequencies.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates n-grams from text files — TokenGenerator","text":"","code":"# Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"test-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The n-gram size n <- 4 # The test file name tfn <- paste0(ed, \"/test-clean.txt\") # The n-gram number is set tg_opts <- list(\"n\" = n, \"save_ngrams\" = TRUE, \"dir\" = ed) # The TokenGenerator object is created tg <- TokenGenerator$new(tfn, tg_opts, ve = ve) # The n-gram tokens are generated tg$generate_tokens()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Generates n-grams from text files — TokenGenerator","text":"objects class cloneable method.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"usage-2","dir":"Reference","previous_headings":"","what":"Usage","title":"Generates n-grams from text files — TokenGenerator","text":"","code":"TokenGenerator$clone(deep = FALSE)"},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Generates n-grams from text files — TokenGenerator","text":"deep Whether make deep clone.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/reference/TokenGenerator.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Generates n-grams from text files — TokenGenerator","text":"","code":"## ------------------------------------------------ ## Method `TokenGenerator$generate_tokens` ## ------------------------------------------------  # Start of environment setup code # The level of detail in the information messages ve <- 0 # The name of the folder that will contain all the files. It will be # created in the current directory. NULL implies tempdir will be used fn <- NULL # The required files. They are default files that are part of the # package rf <- c(\"test-clean.txt\") # An object of class EnvManager is created em <- EnvManager$new(ve = ve, rp = \"./\") # The required files are downloaded ed <- em$setup_env(rf, fn) # End of environment setup code  # The n-gram size n <- 4 # The test file name tfn <- paste0(ed, \"/test-clean.txt\") # The n-gram number is set tg_opts <- list(\"n\" = n, \"save_ngrams\" = TRUE, \"dir\" = ed) # The TokenGenerator object is created tg <- TokenGenerator$new(tfn, tg_opts, ve = ve) # The n-gram tokens are generated tg$generate_tokens()  # The test environment is removed. Comment the below line, so the # files generated by the function can be viewed em$td_env()"},{"path":"https://pakjiddat.github.io/word-predictor/reference/wordpredictor-package.html","id":null,"dir":"Reference","previous_headings":"","what":"wordpredictor: Develop Text Prediction Models Based on N-Grams — wordpredictor-package","title":"wordpredictor: Develop Text Prediction Models Based on N-Grams — wordpredictor-package","text":"framework developing n-gram models text prediction. provides data cleaning, data sampling, extracting tokens text, model generation, model evaluation word prediction. information n-gram models work referred : \"Speech Language Processing\" <https://web.stanford.edu/~jurafsky/slp3/3.pdf>. optimizing R code using R6 classes referred \"Advanced R\" <https://adv-r.hadley.nz/r6.html>. writing R extensions referred \"R Packages\", <https://r-pkgs.org/index.html>.","code":""},{"path":[]},{"path":"https://pakjiddat.github.io/word-predictor/reference/wordpredictor-package.html","id":"author","dir":"Reference","previous_headings":"","what":"Author","title":"wordpredictor: Develop Text Prediction Models Based on N-Grams — wordpredictor-package","text":"Maintainer: Nadir Latif pakjiddat@gmail.com (ORCID)","code":""},{"path":[]},{"path":"https://pakjiddat.github.io/word-predictor/news/index.html","id":"bug-fixes-0-0-3","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"wordpredictor 0.0.3","text":"Disabled caching R Markdown files, causing problems CRAN checks.","code":""},{"path":"https://pakjiddat.github.io/word-predictor/news/index.html","id":"wordpredictor-002","dir":"Changelog","previous_headings":"","what":"wordpredictor 0.0.2","title":"wordpredictor 0.0.2","text":"CRAN release: 2021-06-19","code":""},{"path":"https://pakjiddat.github.io/word-predictor/news/index.html","id":"bug-fixes-0-0-2","dir":"Changelog","previous_headings":"","what":"Bug fixes","title":"wordpredictor 0.0.2","text":"Fixed small bugs causing problems GitHub actions CRAN checks. Removed custom .Rprofile file causing problems GitHub actions. Updated sample code features.Rmd vignette cause issues R CMD Check MacOs. Removed inst/extdata folder .gitignore since causing problems check-standard workflow GitHub. Removed non-standard characters example data-cleaner.R file causing problems CRAN check “Debian Linux, R-devel, clang”. Issues related bug fixes: #318, #319, #320","code":""},{"path":"https://pakjiddat.github.io/word-predictor/news/index.html","id":"wordpredictor-001","dir":"Changelog","previous_headings":"","what":"wordpredictor 0.0.1","title":"wordpredictor 0.0.1","text":"CRAN release: 2021-06-14 Initial Release.","code":""}]
